# My Computer vision projects

This repository includes different types of computer vision projects that was done using OpenCV package of python and tensorflow. Some of them are personal projects and remaining are done by following tutorials.
1) AI Response Drone for SAR
  [Respository](https://github.com/nelson123-lab/AI-response-drone-for-SAR.git)
2) Gender based cleaning algorithm
  [Repository](https://github.com/nelson123-lab/Gender_based_cleaning_algorithm.git)
3) Face Mask 2 level protection for public safety
  [Repository](https://github.com/nelson123-lab/Face-mask-2-level-protection-for-public-safety.git)
4) Stabilizing videos using python
  [Repository](https://github.com/nelson123-lab/Stabilizing_videos_using_deep_learning_python.git)
6) Smile detection using OpenCV
  [Repository](https://github.com/nelson123-lab/Smile-detection-using-OpenCV.git)
8) Different images transformation
  [Repository](https://github.com/nelson123-lab/Different-Image-transformations-using-opencv.git)
9) Edge and contour Detection
  [Repository](https://github.com/nelson123-lab/Edge-and-Contour-Detection.git)
10) Face dectection using OpenCV
  [Repository](https://github.com/nelson123-lab/Face-recognition-using-python)
11) Warp perspective using Opencv
  [Repository](https://github.com/nelson123-lab/warp_perspective)
12) Virtual Paint
  [Repository](https://github.com/nelson123-lab/Virtual_paint)
13) Face Mask detection
  [Repository](https://github.com/nelson123-lab/Face-Mask-detection---3)
14) Image captioning using Flicker dataset
  [Repository](https://github.com/nelson123-lab/Image-Captioning-using-Flicker_dataset)
15) Neural Style Transfer
  [Repository](https://github.com/nelson123-lab/Neural-style-transfer-)
16) Creating videos using text prompts using stable diffusion
  [Repository](https://github.com/nelson123-lab/Creating-Video-with-text-Prompts.git)
17) DCGAN
  [Repository](https://github.com/nelson123-lab/DCGAN_Neural_Network)
18) Lane-Detection-and-Segmentation-for-Autonomous-Vehicles
  [Repository](https://github.com/nelson123-lab/Lane-Detection-and-Segmentation-for-Autonomous-Vehicles.git)
19) Object-Detection-and-Tracking-for-Autonomous-Vehicles
  [Repository](https://github.com/nelson123-lab/Object-Detection-and-Tracking-for-Autonomous-Vehicles.git)
20) Automated-Segmentation-of-Brain-Tumors-in-MRI-Scans
  [Repository](https://github.com/nelson123-lab/Automated-Segmentation-of-Brain-Tumors-in-MRI-Scans.git)
22) Object tracking using YOLO v8
  [Repository](https://github.com/nelson123-lab/YOLOv8_Segmentation_DeepSORT_Object_Tracking)
23) Canny edge detection from scratch
   - Created an algorithm from scratch to detect the edge and compared the results obtained from the OpenCV python package. This includes implementing fuction for each of the steps that are undertaken within the
     the canny edge detection before reaching the final results.
     [Repository](https://github.com/nelson123-lab/Canny-Edge-detection-from-scratch)
24) Hough transform and corner detection
   - This includes hough transform to identify different shapes and the implementation of the harris corner detection.
     [Repository](https://github.com/nelson123-lab/Hough-Transform-and-Harris-Corner-Detection)
25) Image stitching and panorama creation
   - This assignment includes the process of creating a panorama by identifying the key points in different image and combining them to obtain the stitched image.
     [Repository](https://github.com/nelson123-lab/panorama?tab=readme-ov-file)
26) 2D Face Reconstruction
   - This assignment includes the process of reconstructing a face with the help of different number of eigen vectors. This work compares the reconstruction ability of different combination of the eigen reconstructed faces.
     [Repository](https://github.com/nelson123-lab/2D-Face-Reconstruction)
27) Narrating the Unseen: Real-Time Video Descriptions for Visually Impaired Individuals
   - This is the final project of the computer vision course. The paper includes the use of creation of the model setup where the visually impaired people can understand their surroundings in the best way compared to all other existing methods. The system uses GPT-4_vision to do the image captioning of the surrounding in real time.
     [Repository](https://github.com/nelson123-lab/Narrating-the-Unseen-Real-Time-Video-Descriptions-for-Visually-Impaired-Individuals)
